{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "6_AllModels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDWXPWwZC5E0",
        "colab_type": "text"
      },
      "source": [
        "Load required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BjDCgDiXWWaO",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pickle\n",
        "import cv2\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpYKJwUBDCn9",
        "colab_type": "text"
      },
      "source": [
        "Load the zipped data file of the specified type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eauyrJE109CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = \"BOW\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj7rWLcKyFaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not(os.path.exists(dataset)):\n",
        "  with zipfile.ZipFile(dataset + \".zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wBIGyikhZTO2",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "with open(dataset + \"/X.pkl\", \"rb\") as f:\n",
        "  X = pickle.load(f)\n",
        "\n",
        "with open(dataset + \"/y.pkl\", \"rb\") as f:\n",
        "  y = pickle.load(f)\n",
        "\n",
        "X = X.to('cuda').float()\n",
        "y = y.to('cuda').float()\n",
        "y = (y> 10).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9MAGMmOXmSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.arange(0, X.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "train_indices = indices[:(X.shape[0] - 1000)]\n",
        "test_indices = indices[(X.shape[0] - 1000):]\n",
        "\n",
        "y_train = y[train_indices]\n",
        "y_test = y[test_indices]\n",
        "X_train = X[train_indices, :, :]\n",
        "X_test = X[test_indices, :, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3aMGsMODLWR",
        "colab_type": "text"
      },
      "source": [
        "Define an RNN architecture for modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EMCGDjC7Zdhf",
        "colab": {}
      },
      "source": [
        "# Define the network as a class\n",
        "class RNNNetwork(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        super(RNNNetwork, self).__init__()\n",
        "        \n",
        "        #  Recurrent (sequence) layer\n",
        "        self.lstm = torch.nn.LSTM(input_size, 25)\n",
        "\n",
        "        # Two linear layers\n",
        "        self.linear1 = torch.nn.Linear(100, 25)\n",
        "        self.linear2 = torch.nn.Linear(25, 1)\n",
        "\n",
        "        # Dropout of 50% of values\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "        # Sigmoid activation\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    # Performs the forward pass\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.dropout(out)\n",
        "        #out = self.linear1(out.view(len(x), -1))\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out[len(x)-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ1Hoez6LcGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare a model and prepare for training\n",
        "rnn_model = RNNNetwork(X_train.shape[2])\n",
        "rnn_model.to('cuda')\n",
        "rnn_model.train(True)\n",
        "rnn_model.float()\n",
        "\n",
        "# Use the mse loss for a criterion\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "# Define the adam optimizer on the discriminator network\n",
        "rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.000001,\n",
        "                                 betas=(0.9, 0.9999))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ7wHz_TDcnd",
        "colab_type": "text"
      },
      "source": [
        "Train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OzioBvgMaqc",
        "colab_type": "code",
        "outputId": "da91fa7d-8d6d-4963-c725-0b815e270bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Save the losses\n",
        "losses_train = []\n",
        "losses_test = []\n",
        "epochs = 100\n",
        "\n",
        "# Use  100 epochs\n",
        "for i in range(0, epochs+1):\n",
        "    \n",
        "    # Every tenth iteration\n",
        "    if (i % 10 == 0):\n",
        "\n",
        "      # Track the epoch count\n",
        "      print(i, \" of \", epochs)\n",
        "\n",
        "      # Get loss on the training data\n",
        "      epoch_losses_train = []\n",
        "      for j in range(0, int(X_train.shape[0])):\n",
        "      \n",
        "          # Zero the  gradient\n",
        "          rnn_optimizer.zero_grad()\n",
        "\n",
        "          # Select inputs\n",
        "          train_input = X_train[j:(j+1),:, :]\n",
        "          train_input = X_train[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "          train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "          # Skip this input if needed\n",
        "          if train_input.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "          # Get outputs and truth\n",
        "          train_output = rnn_model(train_input)\n",
        "          true_output = y_train[j:(j+1)]\n",
        "          \n",
        "          # Calculate the loss and update the model\n",
        "          loss = criterion(train_output, true_output)\n",
        "          loss.backward()\n",
        "          rnn_optimizer.step()\n",
        "\n",
        "          # Save the loss for this training iteration\n",
        "          epoch_losses_train.append(loss)\n",
        "\n",
        "      # Set training to false\n",
        "      rnn_model.train(False)\n",
        "\n",
        "      # Get loss on the testing data\n",
        "      epoch_losses_test = []\n",
        "      for j in range(0, int(X_test.shape[0])):\n",
        "\n",
        "          # Select inputs\n",
        "          train_input = X_test[j:(j+1),:, :]\n",
        "          train_input = X_test[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "          train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "          # Sip if neceeded\n",
        "          if train_input.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "          # Get outputs and truth\n",
        "          train_output = rnn_model(train_input)\n",
        "          true_output = y_test[j:(j+1)]\n",
        "          \n",
        "          # Calculate the save the loss, but don't update the model\n",
        "          loss = criterion(train_output, true_output)\n",
        "          epoch_losses_test.append(loss)\n",
        "\n",
        "      # Save the losses\n",
        "      losses_train.append((sum(epoch_losses_train) / len(epoch_losses_train)).sqrt())\n",
        "      losses_test.append((sum(epoch_losses_test) / len(epoch_losses_test)).sqrt())\n",
        "\n",
        "      # Allow model to train on the next iterations\n",
        "      rnn_model.train(True)\n",
        "    \n",
        "    else:\n",
        "\n",
        "      # Go across the entire dataset\n",
        "      for j in range(0, int(X_train.shape[0])):\n",
        "      \n",
        "          # Zero the  gradient\n",
        "          rnn_optimizer.zero_grad()\n",
        "\n",
        "          # Select inputs\n",
        "          train_input = X_train[j:(j+1),:, :]\n",
        "          train_input = X_train[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "          train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "          # Skip 0 length sequences\n",
        "          if train_input.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "          # Get hte training output\n",
        "          train_output = rnn_model(train_input)\n",
        "          true_output = y_train[j:(j+1)]\n",
        "          \n",
        "          # Calculate the loss and update the model\n",
        "          loss = criterion(train_output, true_output)\n",
        "          loss.backward()\n",
        "          rnn_optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  of  100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10  of  100\n",
            "20  of  100\n",
            "30  of  100\n",
            "40  of  100\n",
            "50  of  100\n",
            "60  of  100\n",
            "70  of  100\n",
            "80  of  100\n",
            "90  of  100\n",
            "100  of  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQYop2ahOrx5",
        "colab_type": "code",
        "outputId": "84a1ea3e-0bd5-4021-8544-211528c0f72b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Plot the training /testing losses\n",
        "losses_train_plot = np.stack([x.cpu().detach().numpy() for x in losses_train])\n",
        "losses_test_plot = np.stack([x.cpu().detach().numpy() for x in losses_test])\n",
        "plt.plot(losses_train_plot)\n",
        "plt.plot(losses_test_plot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efc704b0160>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niBS4/w+A3oNyEYUQZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3OAGoPsDhQc",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model on both training and testing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P453LRPnOsfO",
        "colab_type": "code",
        "outputId": "17f45e35-3e83-4810-8ab7-148641ba7dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Turn training off\n",
        "rnn_model.train(False)\n",
        "\n",
        "# Track accuracies\n",
        "accuracy_train = []\n",
        "for j in range(0, int(X_train.shape[0])):\n",
        "\n",
        "    # Select inputs\n",
        "    train_input = X_train[j:(j+1),:, :]\n",
        "    train_input = X_train[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "    train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "    # Skip if 0 length\n",
        "    if train_input.shape[0] == 0:\n",
        "      continue\n",
        "\n",
        "    # Calculate hte model output\n",
        "    train_output = rnn_model(train_input)\n",
        "    true_output = y_train[j:(j+1)]\n",
        "\n",
        "    # Check if it was correct\n",
        "    correct = (train_output > 0.5) == true_output\n",
        "    accuracy_train.append(correct.float())\n",
        "\n",
        "# Do same on testing data\n",
        "accuracy_test = []\n",
        "for j in range(0, int(X_test.shape[0])):\n",
        "\n",
        "    # Select inputs\n",
        "    train_input = X_test[j:(j+1),:, :]\n",
        "    train_input = X_test[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "    train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "    if train_input.shape[0] == 0:\n",
        "      continue\n",
        "\n",
        "    if train_input.shape[0] == 0:\n",
        "      continue\n",
        "\n",
        "    train_output = rnn_model(train_input)\n",
        "    true_output = y_train[j:(j+1)]\n",
        "\n",
        "    correct = (train_output > 0.5) == true_output\n",
        "    accuracy_test.append(correct.float())\n",
        "\n",
        "# Calculate overall accuracies\n",
        "print((sum(accuracy_train)[0][0]) / len(accuracy_train))\n",
        "print((sum(accuracy_test)[0][0]) / len(accuracy_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8324, device='cuda:0')\n",
            "tensor(0.8260, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uIuM2mmHAO_",
        "colab_type": "code",
        "outputId": "7feea6c9-badc-46dd-f3e3-48b7542aed20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Calculate accuracies if only guessed 0\n",
        "accuracy_naive = []\n",
        "for j in range(0, int(X_test.shape[0])):\n",
        "\n",
        "    train_output = 0\n",
        "    true_output = y_test[j:(j+1)]\n",
        "    \n",
        "    loss = (train_output > 0.5) == true_output\n",
        "    accuracy_naive.append(loss.float())\n",
        "print(sum(accuracy_naive) / len(accuracy_naive))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.8200], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y84peZo6HP0z",
        "colab_type": "text"
      },
      "source": [
        "Build an MLP for the same purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5mMAgb9BE7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the network as a class for convenience\n",
        "class LinearNetwork(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        super(LinearNetwork, self).__init__()\n",
        "        \n",
        "        # 5 linear layers\n",
        "        self.linear1 = torch.nn.Linear(input_size, 1024)\n",
        "        self.linear2 = torch.nn.Linear(1024, 256)\n",
        "        self.linear3 = torch.nn.Linear(256, 64)\n",
        "        self.linear4 = torch.nn.Linear(64, 16)\n",
        "        self.linear5 = torch.nn.Linear(16, 1)\n",
        "\n",
        "        # Use sigmoid activation between each layer\n",
        "        self.activation = torch.nn.Sigmoid()\n",
        "        \n",
        "    # Performs the forward pass\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.linear1(x)\n",
        "        out = self.activation(out)\n",
        "        \n",
        "        out = self.linear2(out)\n",
        "        out = self.activation(out)\n",
        "        \n",
        "        out = self.linear3(out)\n",
        "        out = self.activation(out)\n",
        "        \n",
        "        out = self.linear4(out)\n",
        "        out = self.activation(out)\n",
        "        \n",
        "        out = self.linear5(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klkG94Z3HXRT",
        "colab_type": "text"
      },
      "source": [
        "For bag of words, collapse along sequence axis (will throw memory error otherwise). If not, just reeshape to a 2 dimensional matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiHJa6sl517w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if dataset == \"BOW\":\n",
        "  X_train = X_train.sum(axis=1)\n",
        "  X_test = X_test.sum(axis=1)\n",
        "else:\n",
        "  X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
        "  X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV8eq711HibQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Training the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hMWhkjKcamTD",
        "colab": {}
      },
      "source": [
        "# Defines a model and prepare for training\n",
        "linear_model = LinearNetwork(X_train.shape[1])\n",
        "linear_model.to('cuda')\n",
        "linear_model.train(True)\n",
        "linear_model.float()\n",
        "\n",
        "# Use the mse loss for a criterion\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "# Define the adam optimizer on the discriminator network\n",
        "linear_optimizer = torch.optim.Adam(linear_model.parameters(), lr=0.001,\n",
        "                                 betas=(0.9, 0.9999))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BjLR3W3u1Xpq",
        "outputId": "7b01b449-5ca0-45bc-c8ef-3f296325ea1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Save the losses\n",
        "losses_train = []\n",
        "losses_test = []\n",
        "epochs = 100\n",
        "\n",
        "# Use  100 epochs\n",
        "for i in range(0, epochs+1):\n",
        "    \n",
        "    # Every tenth iteration\n",
        "    if (i % 10 == 0):\n",
        "\n",
        "      # Track the epoch count\n",
        "      print(i, \" of \", epochs)\n",
        "\n",
        "      # Get loss on the training data\n",
        "      epoch_losses_train = []\n",
        "      for j in range(0, int(X_train.shape[0])):\n",
        "      \n",
        "          # Zero the  gradient\n",
        "          linear_optimizer.zero_grad()\n",
        "\n",
        "          # Select inputs\n",
        "          train_input = X_train[j:(j+1),:]\n",
        "          \n",
        "          # Skip this input if needed\n",
        "          if train_input.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "          # Get outputs and truth\n",
        "          train_output = linear_model(train_input)\n",
        "          true_output = y_train[j:(j+1)]\n",
        "          \n",
        "          # Calculate the loss and update the model\n",
        "          loss = criterion(train_output, true_output)\n",
        "          loss.backward()\n",
        "          linear_optimizer.step()\n",
        "\n",
        "          # Save the loss for this training iteration\n",
        "          epoch_losses_train.append(loss)\n",
        "\n",
        "      # Set training to false\n",
        "      linear_model.train(False)\n",
        "\n",
        "      # Get loss on the testing data\n",
        "      epoch_losses_test = []\n",
        "      for j in range(0, int(X_test.shape[0])):\n",
        "\n",
        "          # Select inputs\n",
        "          train_input = X_test[j:(j+1),:]\n",
        "          #train_input = train_input.reshape(1, train_input.shape[1] * train_input.shape[2])\n",
        "\n",
        "          # Sip if neceeded\n",
        "          if train_input.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "          # Get outputs and truth\n",
        "          train_output = linear_model(train_input)\n",
        "          true_output = y_test[j:(j+1)]\n",
        "          \n",
        "          # Calculate the save the loss, but don't update the model\n",
        "          loss = criterion(train_output, true_output)\n",
        "          epoch_losses_test.append(loss)\n",
        "\n",
        "      # Save the losses\n",
        "      losses_train.append((sum(epoch_losses_train) / len(epoch_losses_train)).sqrt())\n",
        "      losses_test.append((sum(epoch_losses_test) / len(epoch_losses_test)).sqrt())\n",
        "\n",
        "      # Allow model to train on the next iterations\n",
        "      linear_model.train(True)\n",
        "    \n",
        "    else:\n",
        "\n",
        "      # Go across the entire dataset\n",
        "      for j in range(0, int(X_train.shape[0])):\n",
        "      \n",
        "          # Zero the  gradient\n",
        "          linear_optimizer.zero_grad()\n",
        "\n",
        "          # Select inputs\n",
        "          train_input = X_train[j:(j+1),:]\n",
        "          #train_input = train_input.reshape(1, train_input.shape[1] * train_input.shape[2])\n",
        "\n",
        "          if train_input.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "          train_output = linear_model(train_input)\n",
        "          true_output = y_train[j:(j+1)]\n",
        "          \n",
        "          loss = criterion(train_output, true_output)\n",
        "          loss.backward()\n",
        "          linear_optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  of  100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10  of  100\n",
            "20  of  100\n",
            "30  of  100\n",
            "40  of  100\n",
            "50  of  100\n",
            "60  of  100\n",
            "70  of  100\n",
            "80  of  100\n",
            "90  of  100\n",
            "100  of  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJzn7JOGLLp9",
        "colab_type": "text"
      },
      "source": [
        "Also evaluate this model on the training / testing datasets, using the same method as the last one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkxQDYLkbKIA",
        "colab_type": "code",
        "outputId": "cbcae17d-8981-4e76-a564-71b37750f2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "linear_model.train(False)\n",
        "\n",
        "accuracy_train = []\n",
        "for j in range(0, int(X_train.shape[0])):\n",
        "\n",
        "    # Select inputs\n",
        "    train_input = X_train[j:(j+1),:]\n",
        "\n",
        "    if train_input.shape[0] == 0:\n",
        "      continue\n",
        "\n",
        "    train_output = linear_model(train_input)\n",
        "    true_output = y_train[j:(j+1)]\n",
        "\n",
        "    correct = (train_output > 0.5) == true_output\n",
        "    accuracy_train.append(correct.float())\n",
        "\n",
        "accuracy_test = []\n",
        "for j in range(0, int(X_test.shape[0])):\n",
        "\n",
        "    # Select inputs\n",
        "    train_input = X_test[j:(j+1),:]\n",
        "\n",
        "    if train_input.shape[0] == 0:\n",
        "      continue\n",
        "\n",
        "    train_output = linear_model(train_input)\n",
        "    true_output = y_train[j:(j+1)]\n",
        "\n",
        "    correct = (train_output > 0.5) == true_output\n",
        "    accuracy_test.append(correct.float())\n",
        "\n",
        "print((sum(accuracy_train)[0][0]) / len(accuracy_train))\n",
        "print((sum(accuracy_test)[0][0]) / len(accuracy_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8324, device='cuda:0')\n",
            "tensor(0.8260, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}