{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "7_BertRNNModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDWXPWwZC5E0",
        "colab_type": "text"
      },
      "source": [
        "Load required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BjDCgDiXWWaO",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pickle\n",
        "import cv2\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpYKJwUBDCn9",
        "colab_type": "text"
      },
      "source": [
        "Load the zipped data file of the specified type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eauyrJE109CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = \"BERT\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj7rWLcKyFaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not(os.path.exists(dataset)):\n",
        "  with zipfile.ZipFile(dataset + \".zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wBIGyikhZTO2",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "with open(dataset + \"/X.pkl\", \"rb\") as f:\n",
        "  X = pickle.load(f)\n",
        "\n",
        "with open(dataset + \"/y.pkl\", \"rb\") as f:\n",
        "  y = pickle.load(f)\n",
        "\n",
        "X = X.to('cuda').float()\n",
        "y = y.to('cuda').float()\n",
        "y = (y> 10).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9MAGMmOXmSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.arange(0, X.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "train_indices = indices[:(X.shape[0] - 1000)]\n",
        "test_indices = indices[(X.shape[0] - 1000):]\n",
        "\n",
        "y_train = y[train_indices]\n",
        "y_test = y[test_indices]\n",
        "X_train = X[train_indices, :, :]\n",
        "X_test = X[test_indices, :, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3aMGsMODLWR",
        "colab_type": "text"
      },
      "source": [
        "Define an RNN architecture for modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EMCGDjC7Zdhf",
        "colab": {}
      },
      "source": [
        "# Define the network as a class\n",
        "class RNNNetwork(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        super(RNNNetwork, self).__init__()\n",
        "        \n",
        "        #  Recurrent (sequence) layer\n",
        "        self.lstm = torch.nn.LSTM(input_size, 100)\n",
        "\n",
        "        # Two linear layers\n",
        "        self.linear1 = torch.nn.Linear(100, 1)\n",
        "\n",
        "        # Dropout of 50% of values\n",
        "        self.dropout = torch.nn.Dropout(0.8)\n",
        "\n",
        "        # Sigmoid activation\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    # Performs the forward pass\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.linear1(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out[len(x)-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ1Hoez6LcGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare a model and prepare for training\n",
        "rnn_model = RNNNetwork(X_train.shape[2])\n",
        "rnn_model.to('cuda')\n",
        "rnn_model.train(True)\n",
        "rnn_model.float()\n",
        "\n",
        "# Use the mse loss for a criterion\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "# Define the adam optimizer on the discriminator network\n",
        "rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.000001,\n",
        "                                 betas=(0.9, 0.9999))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ7wHz_TDcnd",
        "colab_type": "text"
      },
      "source": [
        "Train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OzioBvgMaqc",
        "colab_type": "code",
        "outputId": "1d4e1e72-14e2-4933-e086-10e1eae592bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Save the losses\n",
        "losses_train = []\n",
        "losses_test = []\n",
        "epochs = 80\n",
        "batch_size=1\n",
        "\n",
        "# Use 50 epochs\n",
        "for i in range(0, epochs+1):\n",
        "    \n",
        "    # Every tenth iteration\n",
        "    if (i % 10 == 0):\n",
        "\n",
        "      # Track the epoch count\n",
        "      print(i, \" of \", epochs)\n",
        "\n",
        "      # Get loss on the training data\n",
        "      epoch_losses_train = []\n",
        "      for j in range(0, int(X_train.shape[0]/batch_size)):\n",
        "      \n",
        "          # Zero the  gradient\n",
        "          rnn_optimizer.zero_grad()\n",
        "\n",
        "          # Select inputs\n",
        "          overall_loss = 0\n",
        "          for k in range(batch_size):\n",
        "            train_input = X_train[(j+k):(j+k+1),:, :]\n",
        "            train_input = X_train[(j+k):(j+k+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "            train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "            # Skip this input if needed\n",
        "            if train_input.shape[0] == 0:\n",
        "              continue\n",
        "\n",
        "            # Get outputs and truth\n",
        "            train_output = rnn_model(train_input)\n",
        "            true_output = y_train[(j+k):(j+k+1)]\n",
        "            \n",
        "            # Calculate the loss and update the model\n",
        "            loss = criterion(train_output, true_output)\n",
        "            overall_loss = overall_loss + loss\n",
        "\n",
        "          overall_loss.backward()\n",
        "          rnn_optimizer.step()\n",
        "\n",
        "          # Save the loss for this training iteration\n",
        "          epoch_losses_train.append(overall_loss)\n",
        "\n",
        "      # Set training to false\n",
        "      rnn_model.train(False)\n",
        "\n",
        "      # Get loss on the testing data\n",
        "      epoch_losses_test = []\n",
        "      for j in range(0, int(X_test.shape[0])):\n",
        "\n",
        "          # Select inputs\n",
        "          train_input = X_test[j:(j+1),:, :]\n",
        "          train_input = X_test[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "          train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "          # Sip if neceeded\n",
        "          if train_input.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "          # Get outputs and truth\n",
        "          train_output = rnn_model(train_input)\n",
        "          true_output = y_test[j:(j+1)]\n",
        "          \n",
        "          # Calculate the save the loss, but don't update the model\n",
        "          loss = criterion(train_output, true_output)\n",
        "          epoch_losses_test.append(loss)\n",
        "\n",
        "      # Save the losses\n",
        "      losses_train.append((sum(epoch_losses_train) / len(epoch_losses_train)).sqrt())\n",
        "      losses_test.append((sum(epoch_losses_test) / len(epoch_losses_test)).sqrt())\n",
        "\n",
        "      # Allow model to train on the next iterations\n",
        "      rnn_model.train(True)\n",
        "    \n",
        "    else:\n",
        "\n",
        "      # Go across the entire dataset\n",
        "      for j in range(0, int(X_train.shape[0]/batch_size)):\n",
        "      \n",
        "          # Zero the  gradient\n",
        "          rnn_optimizer.zero_grad()\n",
        "\n",
        "          # Select inputs\n",
        "          overall_loss = 0\n",
        "          for k in range(0, batch_size):\n",
        "            train_input = X_train[(j+k):(j+k+1),:, :]\n",
        "            train_input = X_train[(j+k):(j+k+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "            train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "            # Skip this input if needed\n",
        "            if train_input.shape[0] == 0:\n",
        "              continue\n",
        "\n",
        "            # Get outputs and truth\n",
        "            train_output = rnn_model(train_input)\n",
        "            true_output = y_train[(j+k):(j+k+1)]\n",
        "            \n",
        "            # Calculate the loss and update the model\n",
        "            loss = criterion(train_output, true_output)\n",
        "            overall_loss = overall_loss + loss\n",
        "\n",
        "          overall_loss.backward()\n",
        "          rnn_optimizer.step()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  of  80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10  of  80\n",
            "20  of  80\n",
            "30  of  80\n",
            "40  of  80\n",
            "50  of  80\n",
            "60  of  80\n",
            "70  of  80\n",
            "80  of  80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3OAGoPsDhQc",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model on both training and testing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P453LRPnOsfO",
        "colab_type": "code",
        "outputId": "04461d37-97f4-459d-a6f3-98214b617f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Turn training off\n",
        "rnn_model.train(False)\n",
        "\n",
        "# Track accuracies\n",
        "accuracy_train = []\n",
        "for j in range(0, int(X_train.shape[0])):\n",
        "\n",
        "    # Select inputs\n",
        "    train_input = X_train[j:(j+1),:, :]\n",
        "    train_input = X_train[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "    train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "    # Skip if 0 length\n",
        "    if train_input.shape[0] == 0:\n",
        "      continue\n",
        "\n",
        "    # Calculate hte model output\n",
        "    train_output = rnn_model(train_input)\n",
        "    true_output = y_train[j:(j+1)]\n",
        "\n",
        "    # Check if it was correct\n",
        "    correct = (train_output > 0.5) == true_output\n",
        "    accuracy_train.append(correct.float())\n",
        "\n",
        "# Do same on testing data\n",
        "accuracy_test = []\n",
        "for j in range(0, int(X_test.shape[0])):\n",
        "\n",
        "    # Select inputs\n",
        "    train_input = X_test[j:(j+1),:, :]\n",
        "    train_input = X_test[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
        "    train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
        "\n",
        "    if train_input.shape[0] == 0:\n",
        "      continue\n",
        "\n",
        "    train_output = rnn_model(train_input)\n",
        "    true_output = y_train[j:(j+1)]\n",
        "\n",
        "    correct = (train_output > 0.5) == true_output\n",
        "    accuracy_test.append(correct.float())\n",
        "\n",
        "# Calculate overall accuracies\n",
        "print((sum(accuracy_train)[0][0]) / len(accuracy_train))\n",
        "print((sum(accuracy_test)[0][0]) / len(accuracy_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8281, device='cuda:0')\n",
            "tensor(0.8340, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGPe0ltsiJE3",
        "colab_type": "text"
      },
      "source": [
        "Get values needed for confusion matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "93ea1304-ee29-476c-d923-2a2d35887fd1",
        "id": "_D-gG_PJzYut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "accuracy_train_0 = accuracy_train[(y_train == 0).cpu().numpy()]\n",
        "accuracy_train_1 = accuracy_train[(y_train == 1).cpu().numpy()]\n",
        "\n",
        "print(sum(accuracy_train_0))\n",
        "print(sum(accuracy_train_1))\n",
        "\n",
        "print(len(accuracy_train_0))\n",
        "print(len(accuracy_train_1))\n",
        "\n",
        "\n",
        "accuracy_test_0 = accuracy_test[(y_test == 0).cpu().numpy()]\n",
        "accuracy_test_1 = accuracy_test[(y_test == 1).cpu().numpy()]\n",
        "\n",
        "print(sum(accuracy_test_0))\n",
        "print(sum(accuracy_test_1))\n",
        "\n",
        "print(len(accuracy_test_0))\n",
        "print(len(accuracy_test_1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2677.0\n",
            "550.0\n",
            "3233\n",
            "664\n",
            "694.0\n",
            "140.0\n",
            "831\n",
            "169\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}