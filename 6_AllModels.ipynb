{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDWXPWwZC5E0"
   },
   "source": [
    "Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T13:33:06.582343Z",
     "start_time": "2020-05-13T13:33:05.831167Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BjDCgDiXWWaO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-70043ccda38b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "import cv2\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IpYKJwUBDCn9"
   },
   "source": [
    "Load the zipped data file of the specified type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eauyrJE109CB"
   },
   "outputs": [],
   "source": [
    "dataset = \"BOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj7rWLcKyFaZ"
   },
   "outputs": [],
   "source": [
    "if not(os.path.exists(dataset)):\n",
    "  with zipfile.ZipFile(dataset + \".zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBIGyikhZTO2"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(dataset + \"/X.pkl\", \"rb\") as f:\n",
    "  X = pickle.load(f)\n",
    "\n",
    "with open(dataset + \"/y.pkl\", \"rb\") as f:\n",
    "  y = pickle.load(f)\n",
    "\n",
    "X = X.to('cuda').float()\n",
    "y = y.to('cuda').float()\n",
    "y = (y> 10).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9MAGMmOXmSQ"
   },
   "outputs": [],
   "source": [
    "indices = np.arange(0, X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:(X.shape[0] - 1000)]\n",
    "test_indices = indices[(X.shape[0] - 1000):]\n",
    "\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "X_train = X[train_indices, :, :]\n",
    "X_test = X[test_indices, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3aMGsMODLWR"
   },
   "source": [
    "Define an RNN architecture for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMCGDjC7Zdhf"
   },
   "outputs": [],
   "source": [
    "# Define the network as a class\n",
    "class RNNNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(RNNNetwork, self).__init__()\n",
    "        \n",
    "        #  Recurrent (sequence) layer\n",
    "        self.lstm = torch.nn.LSTM(input_size, 25)\n",
    "\n",
    "        # Two linear layers\n",
    "        self.linear1 = torch.nn.Linear(100, 25)\n",
    "        self.linear2 = torch.nn.Linear(25, 1)\n",
    "\n",
    "        # Dropout of 50% of values\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "        # Sigmoid activation\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    # Performs the forward pass\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.dropout(out)\n",
    "        #out = self.linear1(out.view(len(x), -1))\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out[len(x)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZ1Hoez6LcGY"
   },
   "outputs": [],
   "source": [
    "# Declare a model and prepare for training\n",
    "rnn_model = RNNNetwork(X_train.shape[2])\n",
    "rnn_model.to('cuda')\n",
    "rnn_model.train(True)\n",
    "rnn_model.float()\n",
    "\n",
    "# Use the mse loss for a criterion\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define the adam optimizer on the discriminator network\n",
    "rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.000001,\n",
    "                                 betas=(0.9, 0.9999))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJ7wHz_TDcnd"
   },
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "_OzioBvgMaqc",
    "outputId": "da91fa7d-8d6d-4963-c725-0b815e270bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  of  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  of  100\n",
      "20  of  100\n",
      "30  of  100\n",
      "40  of  100\n",
      "50  of  100\n",
      "60  of  100\n",
      "70  of  100\n",
      "80  of  100\n",
      "90  of  100\n",
      "100  of  100\n"
     ]
    }
   ],
   "source": [
    "# Save the losses\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "epochs = 100\n",
    "\n",
    "# Use  100 epochs\n",
    "for i in range(0, epochs+1):\n",
    "    \n",
    "    # Every tenth iteration\n",
    "    if (i % 10 == 0):\n",
    "\n",
    "      # Track the epoch count\n",
    "      print(i, \" of \", epochs)\n",
    "\n",
    "      # Get loss on the training data\n",
    "      epoch_losses_train = []\n",
    "      for j in range(0, int(X_train.shape[0])):\n",
    "      \n",
    "          # Zero the  gradient\n",
    "          rnn_optimizer.zero_grad()\n",
    "\n",
    "          # Select inputs\n",
    "          train_input = X_train[j:(j+1),:, :]\n",
    "          train_input = X_train[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
    "          train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
    "\n",
    "          # Skip this input if needed\n",
    "          if train_input.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "          # Get outputs and truth\n",
    "          train_output = rnn_model(train_input)\n",
    "          true_output = y_train[j:(j+1)]\n",
    "          \n",
    "          # Calculate the loss and update the model\n",
    "          loss = criterion(train_output, true_output)\n",
    "          loss.backward()\n",
    "          rnn_optimizer.step()\n",
    "\n",
    "          # Save the loss for this training iteration\n",
    "          epoch_losses_train.append(loss)\n",
    "\n",
    "      # Set training to false\n",
    "      rnn_model.train(False)\n",
    "\n",
    "      # Get loss on the testing data\n",
    "      epoch_losses_test = []\n",
    "      for j in range(0, int(X_test.shape[0])):\n",
    "\n",
    "          # Select inputs\n",
    "          train_input = X_test[j:(j+1),:, :]\n",
    "          train_input = X_test[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
    "          train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
    "\n",
    "          # Sip if neceeded\n",
    "          if train_input.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "          # Get outputs and truth\n",
    "          train_output = rnn_model(train_input)\n",
    "          true_output = y_test[j:(j+1)]\n",
    "          \n",
    "          # Calculate the save the loss, but don't update the model\n",
    "          loss = criterion(train_output, true_output)\n",
    "          epoch_losses_test.append(loss)\n",
    "\n",
    "      # Save the losses\n",
    "      losses_train.append((sum(epoch_losses_train) / len(epoch_losses_train)).sqrt())\n",
    "      losses_test.append((sum(epoch_losses_test) / len(epoch_losses_test)).sqrt())\n",
    "\n",
    "      # Allow model to train on the next iterations\n",
    "      rnn_model.train(True)\n",
    "    \n",
    "    else:\n",
    "\n",
    "      # Go across the entire dataset\n",
    "      for j in range(0, int(X_train.shape[0])):\n",
    "      \n",
    "          # Zero the  gradient\n",
    "          rnn_optimizer.zero_grad()\n",
    "\n",
    "          # Select inputs\n",
    "          train_input = X_train[j:(j+1),:, :]\n",
    "          train_input = X_train[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
    "          train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
    "\n",
    "          # Skip 0 length sequences\n",
    "          if train_input.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "          # Get hte training output\n",
    "          train_output = rnn_model(train_input)\n",
    "          true_output = y_train[j:(j+1)]\n",
    "          \n",
    "          # Calculate the loss and update the model\n",
    "          loss = criterion(train_output, true_output)\n",
    "          loss.backward()\n",
    "          rnn_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T13:33:41.339995Z",
     "start_time": "2020-05-13T13:33:41.196569Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "rQYop2ahOrx5",
    "outputId": "84a1ea3e-0bd5-4021-8544-211528c0f72b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe048366ac8>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training /testing losses\n",
    "plt.plot(np.arange(0,100))  #losses_train_plot)\n",
    "plt.plot(np.arange(5,105)) #losses_test_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3OAGoPsDhQc"
   },
   "source": [
    "Evaluate the model on both training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "P453LRPnOsfO",
    "outputId": "17f45e35-3e83-4810-8ab7-148641ba7dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8324, device='cuda:0')\n",
      "tensor(0.8260, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Turn training off\n",
    "rnn_model.train(False)\n",
    "\n",
    "# Track accuracies\n",
    "accuracy_train = []\n",
    "for j in range(0, int(X_train.shape[0])):\n",
    "\n",
    "    # Select inputs\n",
    "    train_input = X_train[j:(j+1),:, :]\n",
    "    train_input = X_train[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
    "    train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
    "\n",
    "    # Skip if 0 length\n",
    "    if train_input.shape[0] == 0:\n",
    "      continue\n",
    "\n",
    "    # Calculate hte model output\n",
    "    train_output = rnn_model(train_input)\n",
    "    true_output = y_train[j:(j+1)]\n",
    "\n",
    "    # Check if it was correct\n",
    "    correct = (train_output > 0.5) == true_output\n",
    "    accuracy_train.append(correct.float())\n",
    "\n",
    "# Do same on testing data\n",
    "accuracy_test = []\n",
    "for j in range(0, int(X_test.shape[0])):\n",
    "\n",
    "    # Select inputs\n",
    "    train_input = X_test[j:(j+1),:, :]\n",
    "    train_input = X_test[(j):(j+1),:((np.where(train_input.sum(axis=2).cpu().numpy() != -300))[1]).max(), :]\n",
    "    train_input = train_input.reshape(train_input.shape[1], 1, train_input.shape[2])\n",
    "\n",
    "    if train_input.shape[0] == 0:\n",
    "      continue\n",
    "\n",
    "    if train_input.shape[0] == 0:\n",
    "      continue\n",
    "\n",
    "    train_output = rnn_model(train_input)\n",
    "    true_output = y_train[j:(j+1)]\n",
    "\n",
    "    correct = (train_output > 0.5) == true_output\n",
    "    accuracy_test.append(correct.float())\n",
    "\n",
    "# Calculate overall accuracies\n",
    "print((sum(accuracy_train)[0][0]) / len(accuracy_train))\n",
    "print((sum(accuracy_test)[0][0]) / len(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3uIuM2mmHAO_",
    "outputId": "7feea6c9-badc-46dd-f3e3-48b7542aed20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8200], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracies if only guessed 0\n",
    "accuracy_naive = []\n",
    "for j in range(0, int(X_test.shape[0])):\n",
    "\n",
    "    train_output = 0\n",
    "    true_output = y_test[j:(j+1)]\n",
    "    \n",
    "    loss = (train_output > 0.5) == true_output\n",
    "    accuracy_naive.append(loss.float())\n",
    "print(sum(accuracy_naive) / len(accuracy_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y84peZo6HP0z"
   },
   "source": [
    "Build an MLP for the same purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5mMAgb9BE7R"
   },
   "outputs": [],
   "source": [
    "# Define the network as a class for convenience\n",
    "class LinearNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearNetwork, self).__init__()\n",
    "        \n",
    "        # 5 linear layers\n",
    "        self.linear1 = torch.nn.Linear(input_size, 1024)\n",
    "        self.linear2 = torch.nn.Linear(1024, 256)\n",
    "        self.linear3 = torch.nn.Linear(256, 64)\n",
    "        self.linear4 = torch.nn.Linear(64, 16)\n",
    "        self.linear5 = torch.nn.Linear(16, 1)\n",
    "\n",
    "        # Use sigmoid activation between each layer\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "        \n",
    "    # Performs the forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.linear1(x)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.linear2(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.linear3(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.linear4(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.linear5(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klkG94Z3HXRT"
   },
   "source": [
    "For bag of words, collapse along sequence axis (will throw memory error otherwise). If not, just reeshape to a 2 dimensional matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IiHJa6sl517w"
   },
   "outputs": [],
   "source": [
    "if dataset == \"BOW\":\n",
    "  X_train = X_train.sum(axis=1)\n",
    "  X_test = X_test.sum(axis=1)\n",
    "else:\n",
    "  X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "  X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uV8eq711HibQ"
   },
   "outputs": [],
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMWhkjKcamTD"
   },
   "outputs": [],
   "source": [
    "# Defines a model and prepare for training\n",
    "linear_model = LinearNetwork(X_train.shape[1])\n",
    "linear_model.to('cuda')\n",
    "linear_model.train(True)\n",
    "linear_model.float()\n",
    "\n",
    "# Use the mse loss for a criterion\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define the adam optimizer on the discriminator network\n",
    "linear_optimizer = torch.optim.Adam(linear_model.parameters(), lr=0.001,\n",
    "                                 betas=(0.9, 0.9999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "BjLR3W3u1Xpq",
    "outputId": "7b01b449-5ca0-45bc-c8ef-3f296325ea1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  of  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  of  100\n",
      "20  of  100\n",
      "30  of  100\n",
      "40  of  100\n",
      "50  of  100\n",
      "60  of  100\n",
      "70  of  100\n",
      "80  of  100\n",
      "90  of  100\n",
      "100  of  100\n"
     ]
    }
   ],
   "source": [
    "# Save the losses\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "epochs = 100\n",
    "\n",
    "# Use  100 epochs\n",
    "for i in range(0, epochs+1):\n",
    "    \n",
    "    # Every tenth iteration\n",
    "    if (i % 10 == 0):\n",
    "\n",
    "      # Track the epoch count\n",
    "      print(i, \" of \", epochs)\n",
    "\n",
    "      # Get loss on the training data\n",
    "      epoch_losses_train = []\n",
    "      for j in range(0, int(X_train.shape[0])):\n",
    "      \n",
    "          # Zero the  gradient\n",
    "          linear_optimizer.zero_grad()\n",
    "\n",
    "          # Select inputs\n",
    "          train_input = X_train[j:(j+1),:]\n",
    "          \n",
    "          # Skip this input if needed\n",
    "          if train_input.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "          # Get outputs and truth\n",
    "          train_output = linear_model(train_input)\n",
    "          true_output = y_train[j:(j+1)]\n",
    "          \n",
    "          # Calculate the loss and update the model\n",
    "          loss = criterion(train_output, true_output)\n",
    "          loss.backward()\n",
    "          linear_optimizer.step()\n",
    "\n",
    "          # Save the loss for this training iteration\n",
    "          epoch_losses_train.append(loss)\n",
    "\n",
    "      # Set training to false\n",
    "      linear_model.train(False)\n",
    "\n",
    "      # Get loss on the testing data\n",
    "      epoch_losses_test = []\n",
    "      for j in range(0, int(X_test.shape[0])):\n",
    "\n",
    "          # Select inputs\n",
    "          train_input = X_test[j:(j+1),:]\n",
    "          #train_input = train_input.reshape(1, train_input.shape[1] * train_input.shape[2])\n",
    "\n",
    "          # Sip if neceeded\n",
    "          if train_input.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "          # Get outputs and truth\n",
    "          train_output = linear_model(train_input)\n",
    "          true_output = y_test[j:(j+1)]\n",
    "          \n",
    "          # Calculate the save the loss, but don't update the model\n",
    "          loss = criterion(train_output, true_output)\n",
    "          epoch_losses_test.append(loss)\n",
    "\n",
    "      # Save the losses\n",
    "      losses_train.append((sum(epoch_losses_train) / len(epoch_losses_train)).sqrt())\n",
    "      losses_test.append((sum(epoch_losses_test) / len(epoch_losses_test)).sqrt())\n",
    "\n",
    "      # Allow model to train on the next iterations\n",
    "      linear_model.train(True)\n",
    "    \n",
    "    else:\n",
    "\n",
    "      # Go across the entire dataset\n",
    "      for j in range(0, int(X_train.shape[0])):\n",
    "      \n",
    "          # Zero the  gradient\n",
    "          linear_optimizer.zero_grad()\n",
    "\n",
    "          # Select inputs\n",
    "          train_input = X_train[j:(j+1),:]\n",
    "          #train_input = train_input.reshape(1, train_input.shape[1] * train_input.shape[2])\n",
    "\n",
    "          if train_input.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "          train_output = linear_model(train_input)\n",
    "          true_output = y_train[j:(j+1)]\n",
    "          \n",
    "          loss = criterion(train_output, true_output)\n",
    "          loss.backward()\n",
    "          linear_optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJzn7JOGLLp9"
   },
   "source": [
    "Also evaluate this model on the training / testing datasets, using the same method as the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EkxQDYLkbKIA",
    "outputId": "cbcae17d-8981-4e76-a564-71b37750f2a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8324, device='cuda:0')\n",
      "tensor(0.8260, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "linear_model.train(False)\n",
    "\n",
    "accuracy_train = []\n",
    "for j in range(0, int(X_train.shape[0])):\n",
    "\n",
    "    # Select inputs\n",
    "    train_input = X_train[j:(j+1),:]\n",
    "\n",
    "    if train_input.shape[0] == 0:\n",
    "      continue\n",
    "\n",
    "    train_output = linear_model(train_input)\n",
    "    true_output = y_train[j:(j+1)]\n",
    "\n",
    "    correct = (train_output > 0.5) == true_output\n",
    "    accuracy_train.append(correct.float())\n",
    "\n",
    "accuracy_test = []\n",
    "for j in range(0, int(X_test.shape[0])):\n",
    "\n",
    "    # Select inputs\n",
    "    train_input = X_test[j:(j+1),:]\n",
    "\n",
    "    if train_input.shape[0] == 0:\n",
    "      continue\n",
    "\n",
    "    train_output = linear_model(train_input)\n",
    "    true_output = y_train[j:(j+1)]\n",
    "\n",
    "    correct = (train_output > 0.5) == true_output\n",
    "    accuracy_test.append(correct.float())\n",
    "\n",
    "print((sum(accuracy_train)[0][0]) / len(accuracy_train))\n",
    "print((sum(accuracy_test)[0][0]) / len(accuracy_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "6_AllModels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
